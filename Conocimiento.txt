0. Introduction 
The world population is aging. In public health, there are several challenges resulting from this 
demographic change. One major issue concerns the expected increase in the prevalence of many 
chronic health conditions, which reduce the quality of life (World Health Organization, 2006). 
This is particularly concerning for non-communicable diseases (NCDs), which are currently 
“responsible for 80% of the disease burden in the EU countries and the leading causes of 
avoidable premature deaths” (European Commission, n.d.) 
Neurological disorders are NCDs that affect the central and peripheral nervous system, namely 
the brain, spinal cord, nerves, and muscles (World Health Organization, 2006). Some examples 
include dementias such as Alzheimer's disease, epilepsy, stroke, and other cerebrovascular 
diseases, migraine, multiple sclerosis, Parkinson’s disease, brain tumors, and traumatic 
disorders, among others (World Health Organization, 2016). 
Neurological disorders are responsible for 12% of deaths globally (World Health Organization, 
2006). These diseases are equally known for their high impact on disability and dependency. 
For this reason, it can be considered that the measures of prevalence fail to accurately represent 
the burden caused by these diseases (OECD, 2017). Furthermore, it is expected that in future 
years with global growth and aging, this burden will only increase, aggravating human and 
financial costs (Feigin et al., 2019; World Health Organization, 2006). 
The diagnosis of neurological disorders can be challenging, especially when clinical 
manifestation is common to different diseases (Arani et al., 2018; Tolosa et al., 2021). 
Neuroimaging techniques allow doctors to study the brain’s structure and function, being an 
important tool for diagnosis, prognosis, and monitoring of neurological conditions (Middei, 
2022). However, such techniques are expensive (Neiman Institute, 2012; Sailer et al., 2015) 
and time-consuming, as they produce large amounts of data that must be manually analyzed by 
neuroradiologists, among other medical specialists (Lima et al., 2022; Siuly & Zhang, 2016). 
Artificial Intelligence (AI) is an expanding field with numerous applications in neuroradiology. 
The large amount of data generated in health, as well as the increasing computational power 
available, open a window into the possibility of an AI revolution in healthcare (Zaharchuk et 
al., 2018). Expectations for AI in healthcare are tremendous, as it is expected to unlock 
improved efficiency in care delivery while saving costs (Accenture, 2017; Mckinsey, 2020; 
PWC, 2017). 
2 
 
Despite the continuous emergence of new AI solutions for healthcare, it seems that their 
adoption is not keeping up the pace and that implementation issues require addressing (Huisman 
et al., 2021; Shaw et al., 2019). End-users of AI-based digital solutions, such as 
neuroradiologists, are expected to adopt new technologies and integrate them into their 
workflow. Thus, the successful implementation of an AI strategy is heavily dependent on the 
attitudes influencing the acceptance of AI solutions (Lichtenthaler, 2020).  
Previous research has started to look into this matter by studying radiologists’ thoughts and 
expectations regarding the use and future of AI. However, some studies failed to measure 
previous knowledge on AI, thus leading to results that might fall short (Coppola et al., 2021; 
European Society of Radiology, 2019). On the other hand, most studies employed general 
questions about AI without resorting to practical examples, which might have biased the results, 
as well as excluded some radiologists less familiar with the topic from participating (Huisman 
et al., 2021; Waymel et al., 2019). Lastly, none of the studies explored findings through the lens 
of technology acceptance models, which might be a relevant feature for analyzing the 
perceptions and expectations that may condition the adoption behavior. 
The aim of this research is to explore the perceptions and perspectives of neuroradiologists 
towards the adoption of AI in clinical practice. In the scope of analysis, we try to answer three 
research questions, with hypotheses regarding the influence of age on AI use and the impact of 
AI knowledge on the predisposition towards its use. This research is mainly descriptive and 
uses a quantitative method via survey employment to characterize and understand trends in 
neuroradiologists’ viewpoints towards AI adoption. This broad picture of the phenomena can 
be relevant for institutions trying to implement AI in their services by providing insights on 
potential challenges and contributing to well-informed decision-making. 
The chosen methodology will contribute to addressing some of the shortcomings described in 
existing literature through the employment of a survey that is based on technology acceptance 
models, assesses previous knowledge of AI, and includes practical example illustrations to 
encourage participation, even from the participants that are less familiar with AI. 
  
3 
 
1. Literature Review 
1.1.Artificial Intelligence 
Artificial Intelligence (AI) is an umbrella term covering different techniques in which machines 
are able to mimic human cognition, such as learning or problem solving (Chartrand et al., 2017; 
Kaplan & Haenlein, 2019; Krittanawong et al., 2017; Pesapane et al., 2018; Vaishya et al., 
2020). 
Despite many authors’ attempts to describe AI, there is still no consensual definition. For the 
purpose of this work, the definition chosen is the one given by the European Commission, in 
which AI refers to “systems that display intelligent behavior by analyzing their environment 
and taking actions – with some degree of autonomy – to achieve specific goals” (European 
Commission, 2018). Moreover, “AI-based systems can be purely software-based, acting in the 
virtual world (e.g. voice assistants, image analysis software, search engines, speech and face 
recognition systems) or AI can be embedded in hardware devices (e.g. advanced robots, 
autonomous cars, drones or Internet of Things applications)” (European Commission, 2018). 
AI can be thought of as a prediction technology. According to Agrawal et al. (2018) prediction 
is the process of filling in missing information using the existing data to generate new 
information. Shaw et al. (2019) take this framing a step further, mentioning the potential 
involved in predicting estimations of the true information that is missing, which translates into 
taking actions based on more accurate information.  
There is usually no single right answer for which is the best AI tool or strategy to apply, as there 
is always some sort of trade-off involved (Agrawal et al., 2018). In fact, the perceived value of 
using AI tools is based on the trade-off between the potential benefits and risks involved. Thus, 
when benefits are higher than the expected risks, the perceived value of using such tools is 
greater (Esmaeilzadeh, 2020). Popular AI techniques in healthcare applications include, among 
others: Machine Learning (ML), Deep Learning (DL), and Natural Language Processing 
(NLP). 
NLP is an AI subfield that focuses on extracting useful information from narrative text to 
machine-understandable data, so that AI algorithms can be directly performed (He et al., 2019; 
Jiang et al., 2017).  
4 
 
ML is a subfield of AI in which algorithms are trained to learn from data without explicit 
programming, in an attempt to optimize a prediction algorithm between inputs and outputs 
(Chartrand et al., 2017; He et al., 2019; Pesapane et al., 2018). Inputs in healthcare may include 
patient data, such as age, gender, or relevant clinical information, whereas outputs may be the 
desired medical outcomes (Jiang et al., 2017). DL is a technique inside the ML field where 
“multiple processing layers are used to learn representations of data with multiple layers of 
abstraction” (He et al., 2019b, p.31). 
From manufacturing robots to smart assistants, AI has become an essential component of how 
firms operate in several industries and its transformative potential is gradually reshaping how 
business is done. As tasks that were once exclusively performed by humans can now be 
accomplished by machines, sometimes in a faster, better, and more efficient way (Gursoy et al., 
2019; Kaplan & Haenlein, 2019), companies are faced with the decision of integrating AI into 
their business strategy. 
 
1.2.AI in Healthcare 
Artificial Intelligence in Medicine (AIM) can be traced back to the early 1970s (Szolovits, 
2019), with some researchers already predicting a major disruption in the healthcare system 
following the introduction of computers in the field (Schwartz, 1970). In fact, by that time, 
Schwartz (1970) forecasted the possibility that computers could radically change the role of 
doctors, as well as their education and the nature of medical recruitment. 
The emergence of AIM was linked to a response to the progressively pressuring needs in 
healthcare, namely, the demand for improved efficiency and better-quality services. On the 
other hand, the intensifying shortage of medical manpower, aligned with the unbalanced 
geographic distribution of the available physicians, contributed to this growing problem 
(Schwartz, 1970; Szolovits, 2019). 
As modern medicine evolves, life expectancy around the world has improved substantially, and 
the pressure on healthcare systems is higher than ever as they struggle to respond to an ever-
growing demand for their services (Mckinsey, 2020). Bearing this in mind, it becomes evident 
that despite the huge increase in medical complexity and the standards set for it, the cognitive 
capabilities of physicians remain relatively fixed, creating a big challenge in terms of delivering 
the best care (Szolovits, 2019).  
5 
 
From a managerial point of view, there are also concerns regarding the progressively higher 
costs associated with providing increasingly better services to a growing population. According 
to several renowned consulting companies, AI has the power to unlock major costs reduction 
while simultaneously improving quality and access to health services (Accenture, 2017; 
Mckinsey, 2020; PWC, 2017). Furthermore, the increasing availability of large digital datasets 
and the developments made in computing power make it possible for this paradigm shift to take 
place in healthcare (Allen et al., 2019; Jiang et al., 2017; Kulkarni et al., 2020).  
The advantages of AI are a widely discussed topic in medical literature. Through AI algorithms, 
machines can be trained and learn from health data to obtain relevant insights, even in situations 
where the human observer would not be able to obtain them (He et al., 2019; Jiang et al., 2017).  
When applied to the medical field, AI tools can perform a wide range of functions, assisting 
doctors in clinical decisions such as diagnosis, prioritizing tasks, treatment protocols, or risk 
prediction (Ramesh et al., 2004; Rong et al., 2020). In some cases, AI may perform tasks in a 
faster, more consistent, and more accurate way than physicians. This means that automating 
specific tasks might be the key to reducing medical error and improving productivity as well as 
allocation of human capital, especially when tasks are low in complexity but very time-
consuming (He et al., 2019; Rong et al., 2020). 
As machines may potentially outperform humans in routine tasks, speculation grows on 
whether doctors will be replaced by AI (Bluemke, 2018; Yu et al., 2018). However, despite the 
overall excitement around the potential of these emerging technologies and their current 
applications, it is most likely that AI will augment physicians’ capacities instead of fully 
replacing them (He et al., 2019; Jiang et al., 2017; Shaw et al., 2019). This happens because 
most AI tools are designed to undertake a specific task rather than an entire job position. Indeed, 
the full replacement of a healthcare professional would imply that every single task of that 
specific position would be automated or allocated to another human (Shaw et al., 2019). 
Healthcare providers and professionals may need to prepare for a future in which the workforce 
will see a synergy between man and machine, and new “hybrid” roles will most likely emerge 
(Jha & Topol, 2016; Mckinsey, 2020).  
Although this synergy is still far from reality, current intelligent technologies in healthcare are 
living proof that the sector is experiencing the impact of AI. From wearable devices that monitor 
patients’ sleep patterns and heart rate to algorithms that can successfully identify abnormalities 
6 
 
in medical imaging and robotic arms used in surgeries, AI applications can be integrated into 
every stage of health prevention, regardless of whether they are more patient or clinician 
centered. 
Healthcare needs to be safe, effective, equitable, patient-centric, timely, and efficient (Institute 
of Medicine, 2001) and in most of these directions, it is expected that AI may contribute as a 
powerful leverage tool.  
 
1.3.AI applications in Neuroradiology 
Neuroradiology is a medical specialty in Portugal or subspecialty in other countries, and it 
focuses on diagnosing abnormalities of the head, brain, spine, and neck through medical 
imaging. This is one of the leading medical fields in terms of the diversity and number of AI 
applications (Olthof et al., 2020; Pesapane et al., 2018). According to the U.S Food and Drug 
Administration, medical imaging refers to several different technologies used to view the 
human body in order to diagnose, monitor, or treat medical conditions. These include 
Ultrasound Imaging, Magnetic Resonance Imaging, Radiography, and Computed Tomography, 
among others (Food and Drug Administration, 2018). 
As researchers continue searching for new or improved ways to innovate healthcare more and 
more studies are being published encouraging the emergence of clinical AI tools, already 
commercially available in the neuroradiological field (Kaka et al., 2021). 
In the AIM field, specialties that heavily rely on medical imaging, including radiology, have 
been particularly studied by researchers in the discipline of computer vision, which tries to 
communicate visual understanding to a computer system (Chartrand et al., 2017; Kulkarni et 
al., 2020). Visual task approaches allow radiologists to extract relevant insights from medical 
images, such as details or patterns unrecognizable to the human eye, so new information can be 
added to imaging reports (Noguerol et al., 2019). 
DL has shown potential in this field, as it can be applied to simpler tasks, like image 
segmentation, and more complex tasks, including image detection, classification, generation, 
or reconstruction, among others (Yao et al., 2020). When applied to clinical practice, these tools 
aim not only at improving timelier diagnosis by shortening time-consuming image analysis but 
also at reducing medical errors. At the same time, they provide doctors with the ability to deal 
with impractical datasets (Noguerol et al., 2019; Yao et al., 2020). Another major potential 
7 
 
involved in this sort of technology concerns the improvement of patients’ access to imaging, 
particularly in remote areas (Liew, 2018). 
In recent years, multiple studies have been published on the potential of DL on neuroimaging, 
within a wide range of neurological problems, like intracranial hemorrhage, vascular lesions, 
or head and neck tumors (Kaka et al., 2021; Yao et al., 2020). Improvements made in such 
techniques are contributing to developments in the detection and treatment of neurological 
disorders such as stroke (Herweh et al., 2016; Tang et al., 2011), multiple sclerosis (Beadnall 
et al., 2019), or Alzheimer’s disease (Liu et al., 2018). 
However, AI applications in radiology and its subspecialties go far beyond medical imaging as 
they show potential to impact a broader range of processes involved in the clinical workflow 
(Choy et al., 2018). These include more general tasks such as order scheduling, patient 
screening, consulting with other clinicians, or report elaboration. This is important, as 
radiologists spend considerable time on tasks unrelated to image interpretation, that could 
potentially be assisted by AI technologies (Kulkarni et al., 2020; Noguerol et al., 2019).   
In time, it is expected that a range of AI tools will be adopted by neuroradiologists in their 
workflow, with a positive overall impact on productivity while also improving the quality of 
services and patient satisfaction (Choy et al., 2018). However, there are still numerous 
challenges that need to be addressed for the large-scale adoption of these technologies to take 
place. Research shows that, among others, regulatory obstacles and ethical issues concerning 
patients’ safety and privacy are still a work in progress. On the other hand, the lack of incentives 
for data sharing, the need for data standardization frameworks, and the difficulties experienced 
in the explainability of “black-box” models are also major challenges to tackle in the future (He 
et al., 2019; Jiang et al., 2017; Noguerol et al., 2019; Yu et al., 2018).   
 
  
8 
 
1.4.AI from the medical community perspective 
When thinking of the adoption of AI in clinical practice, it becomes evident that the healthcare 
workforce will play a major role in the integration, use, and improvement of such tools. “The 
greatest challenge to AI in these healthcare domains is not whether the technologies will be 
capable enough to be useful, but rather ensuring their adoption in daily clinical practice”  
(Davenport & Kalakota, 2019, p.97). 
Research studies regarding the implementation of information technologies such as electronic 
medical records (EMR) have shown that the success or failure heavily depends on the extent of 
physicians’ resistance to its application (Lapointe & Rivard, 2006). In a study conducted with 
family physicians on their attitudes and perceptions towards EMR, low perceived usefulness, 
as well as lack of belief in the abilities of the tool were pointed out as possible factors affecting 
the usage of EMR (Loomis et al., 2002). 
In the light of such studies, doctors’ perceptions and beliefs on AI tools are most likely a 
relevant insight for researchers and health leaders trying to integrate AI into daily clinical 
practice. Indeed, some authors mention that in the medical community there is still some 
reluctance to use AI technologies (Noguerol et al., 2019; Pesapane et al., 2018). Therefore, it is 
important to understand and explore factors building up to negative perceptions, as investing in 
AI technologies without acknowledging potential issues in acceptance and intention to use 
might turn out to be a waste of resources (Esmaeilzadeh, 2020). 
Despite results showing overall general positive attitudes towards the use of AI, recent studies 
within the radiological community have identified a latent uncertainty among doctors (Coppola 
et al., 2021) highlighting concerns regarding the lack of AI knowledge and training (Huisman 
et al., 2021; Waymel et al., 2019).  
 
1.5.Technology Acceptance Models 
The Technology Acceptance Model (TAM) was proposed in 1989 by Davis, and it aims to 
explain technology acceptance behavior. TAM posits a simple framework where the adoption 
of technology is determined by behavior intention, which in turn is affected by two main 
variables: perceived usefulness (PU) and perceived ease of use (PEU) (Davis, 1989; King & 
He, 2006). PU is defined as the extent to which a person finds that using the technology will 
9 
 
improve his or her performance, whereas PEU is related to the extent to which a person finds 
that using the technology will be easy and effort-free. Additionally, TAM theorizes that PU is 
also influenced by PEU, in the sense that, as technology becomes easier to work with, it will 
also prove to be more useful (Venkatesh & Davis, 2000). 
Despite TAM being broadly used, partially due to its simplicity and explainability, research in 
the area of technology acceptance models grew, to the point where researchers had to choose 
between numerous adaptations of models or the original ones, ignoring contributions from the 
alternative constructs (Venkatesh et al., 2003). This was the motivation behind the proposal of 
the Unified Theory of Acceptance and Use of Technology (UTAUT), a synthesized revision of 
the existing models. 
UTAUT proposes four main predicting factors on behavioral intention and user acceptance: 
performance expectancy (PE), effort expectancy (EE), social influence (SI), and facilitating 
conditions (FC). PE, in resemblance to PU, is defined as the extent to which a user believes that 
using the technology will improve his job performance. EE is much similar to PEU, as it 
concerns the easiness of using the technology. SI is the extent to which someone perceives that 
important others believe he should use the technology. Finally, FC relates to organizational and 
technical infrastructures and their perceived supporting role in technology usage by the 
individual. Additionally, FC is the only variable that influences directly the usage, rather than 
the behavioral intention behind it (Venkatesh et al., 2003). 
Despite being widely used for assessing the acceptance of general technologies, studies that 
make an intersection between technology acceptance models and AI acceptance by healthcare 
professionals are rare. 
 
  
Perceived 
Usefulness 
Perceived Ease of 
Use 
Behavior intention 
Actual use of 
Technology 
Performance 
Expectancy 
Facilitating Conditions 
Social Influence 
Effort Expectancy 
Performance Expectancy 
ffort Expectancy 
TAM 
UTAUT 
Figure 1- Simplified scheme of technology acceptance models (adapted from Davis et al., 1989 and 
Venkatesh et al., 2003) 
10 
 
1.6.Previous studies  
While research on new innovative AI health products and their potential advances, it seems as 
though less attention has been paid to the user on the other side, especially when it comes to 
healthcare professionals. This is perceptible by the reduced number of studies on doctors’ 
perceptions and attitudes towards the use of AI. Interestingly, there are a few studies published 
on this topic that focus on radiologists, possibly because this is a data-driven specialty that relies 
on medical imaging, one of the most promising areas for AI (Pesapane et al., 2018). 
Coppola et al. (2021) surveyed 1032 members of the Italian Society of Medical and 
Interventional Radiology on their expectations and opinions about AI. The results highlighted 
that a considerable amount of 18.0% of the respondents was uncertain about the adoption of 
AI, whereas 5.0% were unfavorable. Identified potential issues included concerns regarding 
poorer professional reputation, when compared to other medical specialties, and workload 
increase as a consequence of AI system maintenance and data analysis. In general, the results 
showed an overall favorable opinion towards AI adoption. However, the lack of additional 
questions related to AI-specific knowledge or familiarity was a limitation, as it prevented the 
authors from finding any correlation between previous knowledge and overall attitude towards 
AI.    
In a study conducted on 270 French radiologists regarding their expectations, perceptions, and 
knowledge of AI, 73.3% of the respondents agreed they had insufficient knowledge of AI, and 
a vast majority of 94.4% considered the possibility of attending generic education on the field 
(Waymel et al., 2019). As to the overall opinion, results showed an optimistic forecast, with 
expected improvements in the daily workflow of radiologists. Nonetheless, the authors pointed 
out the likelihood of a biased overall opinion on AI, as most respondents had to answer 
questions on a topic to which they claimed to have insufficient knowledge.  
At an international level, the European Society of Radiology (2019) analyzed 675 answers from 
their members on a survey about expectations for AI in 5-10 years. Results showed that almost 
half of the participants (47.6%) did not currently use AI, in contrast to 20.4% who did, and 
30.4% responded that they were planning to use it. Relevant insights from the study included 
perceptions of the expected reduction in job opportunities (41.9%) and expectations that AI will 
make radiologist-patient interaction more impersonal (33.7%). As the scope of this study was 
more future-oriented, one important limitation concerned the time barrier, as most questions 
were aimed at forecasted opinions and not at the current viewpoint on the topic.  
11 
 
More recently, Huisman et al. (2021) investigated the knowledge and attitudes of radiologists 
and residents in 54 mostly European countries. Among the main conclusions, results showed 
that low AI-specific knowledge appears to be associated with fear, whereas a higher knowledge 
in the AI field seems to be associated with a positive attitude about AI. It is important to point 
out that in this study one major limitation concerned the measurement of AI-specific 
knowledge. AI knowledge was measured based on a single question, regarding self-perceived 
knowledge. This imprecision in measurement is particularly relevant in topics where there is 
still a lack of a consensual definition, such as AI, as it increases the subjectivity around the 
concept. 
Based on the above studies, it becomes apparent that AI knowledge and training was a common 
topic, perceived as limited among several radiologists. In addition to this, some authors reported 
the lack of or the subjectivity involved in assessing AI-specific knowledge, as most questions 
were based on self-perception. Despite overall positive perceptions of radiologists towards AI, 
there are still concerns worth further exploring. It is also worth mentioning that none of the 
above studies were based on Technology Acceptance Models, which could be an important 
feature to a better understanding of the perceptions building up to a more willing mindset for 
AI adoption.     
The following table summarizes the main similar studies found and its results. 
Author 
(Year) 
N Type of doctor Main findings 
Coppola et al. 
(2021) 
1032 Radiologists 
 Radiologists had an overall positive attitude to AI 
implementation.  
 Main perceived concerns included poorer reputation (60.3%) 
and increased costs and workload (39.0%).  
 Radiologists agreed that AI needs specific regulation for 
integration into clinical practice. 
Doraiswamy 
et al.  
(2020) 
791 Psychiatrists 
 About half of the sample believed that AI would substantially 
impact their job but only 3.8% felt that their jobs would 
become obsolete.  
 Psychiatrists were skeptical that AI could perform their tasks 
with the same performance, especially in empathic care.  
 Results showed uncertainty about the risk-benefit of AI in 
mental health. 
European 
Society of 
Radiology 
(2019) 
675 Radiologists 
 Participants expected AI to impact reporting workload 
(74.7%), job opportunities (55.6%), and that it would change 
the profile of radiologists into a more clinical one (53.9%). 
 Only 20.4% of the sample reported using AI.  
 Radiologists agreed they should be involved in the AI 
solutions development and validation.  
12 
 
Huisman et al. 
(2021) 
1041 Radiologists 
 Limited knowledge about AI appeared to be associated with 
fear, whereas intermediate to advanced knowledge about AI 
seemed to be associated with a positive attitude towards AI. 
 Age appeared to be negatively associated with having a 
positive attitude towards AI. 
Oh et al. 
(2019) 
669 Physicians1 
 Familiarity with AI was low, despite many respondents seeing 
AI as useful in healthcare (73.4%) 
 The main expected applications for AI included helping 
diagnose (83.4%) and making treatment plans (53.8%). 
 In general, participants didn’t think AI could replace a doctor, 
and most (78.9%) would favor human opinion over AI in 
medical decisions.   
Sarwar et al. 
(2019) 
487 Pathologists 
 Respondents were generally optimistic about AI, with 73.3% 
reporting interest or excitement in this topic. 
 Participants emphasized that, before an AI implementation, 
issues such as insufficient AI training and lack of regulation 
need to be addressed. 
Tasdogan  
(2020) 
68 Anesthesiologists 
 Only 36.8% of the participants considered having sufficient 
AI-specific knowledge 
 Respondents agreed that AI would drastically impact all fields 
of medicine (64.7%), but only 2.9% foresaw a complete 
replacement of physicians by AI. 
Waymel et al. 
(2019) 
270 Radiologists 
 Insufficient knowledge about AI was reported by 73.3% of 
the sample 
 AI was expected to have a positive impact on the future 
practice of radiology (79.3%)  
 Expectations focused on decreasing medical errors (81%), 
time-saving in exams interpretation (74.4%), and increasing 
doctor-patient time (52.2%) 
 
Table 1-  Similar studies and its main findings 
  
                                                 
1 The medical specialty of the participants is not specified by the authors. 
13 
 
2. Methodology 
The nature of this research is mainly descriptive and uses a quantitative method to understand 
the perceptions and perspectives of neuroradiologists regarding the use of AI in clinical 
practice. In descriptive studies, the focus of the research is to specify the manifesting 
characteristics of a certain phenomenon (Sampieri et al., 2012), which is in line with the aim of 
this thesis, and by doing so, expand the in-depth understanding of the phenomena. 
Three research questions were conceptualized and the following hypotheses were formulated: 
 
To help address the questions, an online survey was designed for data collection.  “Surveys are 
a convenient method for collecting quantitative data about perceptions and opinions of 
participants” (Mellinger & Hanson, 2017, p.30). Moreover, a survey-based approach allows 
quantifying answers, thus being a useful insight to understand trends in neuroradiologists’ 
viewpoint towards AI adoption.  
Research Questions Hypotheses 
RQ1: What are the perceptions and 
perspectives of neuroradiologists towards 
the use of AI in their clinical practice? 
--- 
RQ2:  Does the age of neuroradiologists 
influence their use of AI in clinical 
practice? 
H1: A neuroradiologist’s use of AI is influenced 
by his/her age. 
RQ3: What is the impact of specific-AI 
knowledge of neuroradiologists on their 
predisposition towards its use? 
H2: A positive attitude towards the use of AI is 
influenced by previous knowledge about AI.  
H3: The fear of AI is influenced by previous 
knowledge about AI. 
Table 2 - Research questions and hypotheses 
14 
 
2.1.Survey development and distribution 
The survey was developed based on previous relevant literature, such as previous similar 
studies, as well as existing models on technology acceptance. The script was validated by two 
experts who fulfilled the pilot survey and after fine-tuning some questions, it was published. It 
was designed in the Qualtrics web application and it was available for seven weeks, from 
December 20th to February 6th. The distribution of the survey was done through two main 
channels: societies of neuroradiologists and LinkedIn.  
A total of 17 societies of neuroradiologists were contacted, from which 7 responded and 5 
agreed to share the survey through their members. In the LinkedIn platform, a private message 
was sent to the estimated amount of 300 neuroradiologists. The criteria used for sending a 
message included both being a neuroradiologist, as well as having the current job position 
located in a European country. The standard email sent to the organizations’ presidents as well 
as the message sent to neuroradiologists through LinkedIn can be found in Appendixes I and 
II. Figure 2 summarizes the methodology process.   
 
 
* European Society of Neuroradiology, Portuguese Society of Neuroradiology, Spanish Society of 
Neuroradiology, French Society of Neuroradiology, and Danish Society of Neuroradiology 
Figure 2. Methodology process 
Previous 
studies 
Survey 
design 
Technology 
Acceptance 
Models 
Survey 
validation Distribution 
Societies of 
Neuroradiologists* 
Linkedin 
Data 
collection 
Data 
analysis 
Pilot 
survey 
Fine 
tuning 
15 
 
2.2.Survey structure 
The survey’s structure includes four main blocks aiming to assess: demographics (1), 
knowledge (2), perceptions (3), and perspectives (4). 
The first block collects demographic information, such as age, gender, workplace 
characteristics and specific background. 
The second block aims to assess neuroradiologists’ knowledge about AI through a set of 3 
questions where we assess: self-perceived knowledge on a Likert scale ranging from 1 (very 
insufficient) to 5 (very good); the definition of ML (in which only one of the answers is 
accurate) and current experience with AI tools. 
The third block contains several questions regarding perceptions about the use of AI in clinical 
practice. The first seven questions are affirmations to which the respondents must specify their 
agreement on a Likert scale from 1 (strongly disagree) to 5 (strongly agree), while the last 
question is a multiple choice. Questions 11 to 16 are an adaptation based on TAM and UTAUT, 
as shown in Table 2. 
Questions Assess 
Q11: I think that AI tools improve diagnosis accuracy (i.e. 
decrease medical error) 
Performance Expectancy 
Q12: I think that AI tools accelerate some tasks, thus improving 
time response to patients 
Q13: Working with AI tools requires more effort (e.g. time 
invested) than working without AI tools 
Effort Expectancy 
Q14: My institution promotes the use of AI in clinical practice 
Facilitating conditions 
Q15: My institution has the right conditions (e.g. good quality 
dataset, capable IT services, advanced digital solutions) to 
support AI adoption in clinical practice 
Q16: I feel pressured by my colleagues or institution to use AI in 
daily clinical practice 
Social Influence 
Table 3 – Questions based on TAM and UTAUT 
We also included some questions regarding the learning needs of AI, such as the number of 
hours that should be dedicated to this matter, or the most relevant topics to be taught.  
16 
 
The fourth and last block of the survey explores the perspectives and concerns of 
neuroradiologists. It starts with a 50 seconds video in which an expert on AI is talking about its 
potential and applications, mentioning that “many conditions could be AI-diagnosed.”. This 
block mainly focuses on hypothetical situations in which participants are asked about their 
expectations, recommendations, emotions, and reactions before different scenarios through 
multiple-choice questions.  
2.3.Survey analysis 
After data collection, descriptive statistics were used to characterize the sample in the four main 
blocks of assessment. Moreover, for both RQ2 and RQ3, three different Chi-Square tests were 
performed under a confidence interval of 95%. The Chi-Square test is a commonly used 
statistical tool for analysing the existence of an association between categorical variables 
(Franke et al., 2012). In order to conduct robust statistical tests, the following variables were 
contemplated: 
 
 Age 
The sample was divided into 2 groups: people with less than 44 years old and people above 
45 years old. 
 
 Knowledge about AI 
We considered that a neuroradiologist had knowledge about AI when at least 2 out of 3 of 
the following criteria were met: 
- Having assessed one’s knowledge as sufficient or higher (Q8 – self-evaluation); 
- Having chosen the correct definition of ML in Q92 (hetero-evaluation); 
- Using AI tools in clinical practice (Q10a) 
 
 AI use 
We considered that respondents use AI if they replied with “Yes” to Q10a: Do you use AI-
based tools in your clinical practice? (e.g. a software that detects, quantifies or classifies a 
certain lesion based on medical imaging) 
 
                                                 
2 “AI branch in which algorithms are trained to learn from data without explicit programming” 
17 
 
 Fear of AI 
Fear of AI was considered in participants that selected the option “Afraid” in Q20: How 
does this scenario make you feel? Choose up to 3 options 
 
 Positive attitude towards AI 
We considered that a participant had a positive attitude if he selected a positive reaction to 
Q23a: What are your initial thoughts?3 and agreed to at least 2 out of 3 of Q11-Q13. 
In the Q13 answer scale, the lowest agreements correspond with a higher acceptance. Thus, 
we inverted its answer scale to match positively with Q11 and Q12. 
 
 
  
                                                 
3 “I want to be involved”, “I want to help push this process forward”, or “Wow! I want to be ahead of the game, I 
am in!” 
18 
 
3. Results 
3.1.Demographics 
A total of 184 complete survey responses were collected. Gender distribution was slightly 
unbalanced, with 62.5% of male respondents. Age distribution revealed that 58.7% of 
neuroradiologists were below 44 years old and that the median age category was 35-44 years 
old. A minority of respondents (5.4%) were above 65 years old. 
 
Specialists represented 89.7% of the sample and 10.3% were interns. In terms of further 
academic learning, almost half of the respondents (46.7%) claimed to have an advanced specific 
background (such as a research fellowship or a PhD). As for the main site of professional 
activity, public hospitals accounted for 77.7% of responses and private hospitals for 14.7%.  
 
 
0% 5% 10% 15% 20% 25% 30% 35% 40% 45%
Public hospital
Private hospital
Other
No advanced specific background Advanced specific background
Graph 2 -  Distribution of main working site and advanced specific background in the sample 
0,0%
5,0%
10,0%
15,0%
20,0%
25,0%
30,0%
35,0%
40,0%
25 - 34y 35 - 44y 45 - 54y 55 - 64y ≥ 65y
Female Male Rather not say
Graph 1 - Age and gender distribution in the sample 
19 
 
The geographical distribution of the respondents’ working countries included a total of 25 
European countries, with its distribution represented on Graph 3.  
*Finland, Hungary, Ireland, Romania, Slovakia, and Sweden 
 
3.2.Knowledge about AI 
The following graph reports the self-perceived knowledge about AI in the sample. 
  
Graph 4 - Answer distribution to Q8: How would you classify your knowledge about AI? 
0%
2%
4%
6%
8%
10%
12%
14%
16%
18%
Graph 3 - Distribution of the working countries in the sample 
42,9%
57,1%
Very insufficient
6,0%
Insufficient
37,0%
Sufficient
36,4%
Good
17,9%
Very good
2,7%
20 
 
As for the definition of ML, results show that 56.0% of the sample chose the most accurate 
response, while 41.8% believed ML to be a broader term than AI (Graph 5). 
 
The results for AI use were almost balanced, with a positive answer (Yes) from 48.4% of 
neuroradiologists. From the participants that claimed to be using AI, results showed that a 
majority of 68.5% are actually using AI with a high frequency (at least every week). For more 
information, see Graph 6. 
 
 
Graph 6 – AI use and frequency of use in the sample 
0% 10% 20% 30% 40% 50% 60%
AI branch in which algorithms are trained to learn from
data without explicit programming
Broader term that includes all AI technologies that can
learn from data and recognize patterns
Other
It is the same as AI (i.e. they are synonyms)
Graph 5 - Answer distribution to Q9: How would you define “Machine Learning”? 
43,5%
2,7%5,4%
48,4%
In every case that I work on; 1,1%
Everyday; 17,4%
Every week; 14,7%
Few times a month; 
12,0%
Few times a year; 3,3%
No
Not sure
Not that I am aware of
Yes
21 
 
3.3.Perceptions about AI 
The following graph summarizes the responses to Q11-Q16 related to perceptions about AI.  
* good quality dataset, capable IT services, advanced digital solutions 
 
Concerning AI education, 59.8% of the neuroradiologists acknowledged that AI training should 
be included in the medical curriculum. When asked about the number of hours that AI training 
should replace in traditional medical training, responses showed that the options with the lowest 
time periods were usually the most voted.  
Graph 7 - Distribution of the perceptions about AI in the sample (Q11-Q16) 
0% 20% 40% 60% 80% 100%
Q16: I feel pressured by my colleagues or institution to use AI in clinical
practice
Q15: My institution has the right working conditions*  to support AI
adoption in clinical practice
Q14: My institution promotes the use of AI in clinical practice
Q13: Working with AI tools requires more effort (e.g. time invested)
than working without AI tools
Q12: I think that AI tools accelerate some tasks thus improving time
response to patients
Q11: I think that AI tools improve diagnostic accuracy (i.e. decrease
medical error)
Strongly agree Agree Neither agree nor disagree Disagree Strongly disagree
17,9%
22,3%59,8%
10h; 20,1%
20h; 15,2%
40h; 12,5%
70h; 5,4%
> 100h; 6,5%
Disagree/Strongly disagree
Neither agree nor disagree
Agree/Strongly agree
Graph 8 - Answer distribution to Q17a: There should be AI training in the medical curriculum 
and Q17b: How many hours of traditional medical training should be replaced by AI training? 
22 
 
Concerning the AI topics that should be taught, almost half of the sample chose “Limitations 
and challenges” (47.3%), followed by “Understanding the construction of algorithms” (21.7%) 
and “Taking the lead in AI solutions development” (19%). 
 
3.4.Perspectives about AI 
The following graph illustrates the answer distribution to Q19: In this video we hear Dr. Eric 
Topol, an expert in digital medicine, saying that “many conditions could be AI-diagnosed”. 
When do you think this will become a reality? 
 
When confronted with this possible scenario, the most frequently stated emotions were 
excitement (44.6%), motivation (34.2%), and indifference (20.1%). Fear was the fourth most 
stated emotion, voted by 12.5% of the respondents.  
0%
10%
20%
30%
40%
50%
Excitement Motivation Indifference Fear Demotivation Relief Other
72,8%
23,4%
3,8%
Up to 10 years
15 or more years
Never
Graph 10 - Distribution of reported emotions in an AI scenario 
Graph 9 - Forecast on the time until many conditions can be AI-diagnosed (Q19) 
23 
 
When faced with the statement that neuroradiologists who use AI will replace neuroradiologists 
who don’t”, more than half the sample (52.2%) agreed this scenario to be likely (n=74) or very 
likely (n=22). Graph 11 shows the overall answer distribution to this question. 
 
Regarding concerns with AI, the most highlighted ones were related to technological 
malfunctions (78.8%) lack of regulation (51.1%), and ethical issues with data privacy and 
security (39.1%). For more information about expressed concerns with AI see Graph 12. 
 
52,2%
28,3%
19,6%
Very likely/Likely
Very unlikley/Unlikely
No opinion
Graph 11 - Answer distribution to Q21: How likely is it that neuroradiologists who use 
AI will replace neuroradiologists who don't? 
0% 10% 20% 30% 40% 50% 60% 70% 80% 90%
Technological concerns regarding AI malfunction (e.g. making
a wrong decision based on an AI error
Regulation concerns (e.g. lack of standard regulation, liability
issues)
Ethical issues related to patients' data privacy and security
Lower salaries and/or job opportunities
Threat to doctor-patient relationship
Lower reputation, as neuroradiologists would no longer
perform certain tasks
Other
Graph 12  - Answer distribution to Q22: In this scenario of AI automation what would be your major 
concerns? Choose up to 3 options 
24 
 
The following graph illustrates the recommended steps for accelerating an AI strategy. 
Label: HCP – Healthcare professionals 
  
  
0% 10% 20% 30% 40% 50% 60%
Upgrade the curent IT infrastructures
Promote the collaboration of HCP in AI solutions
Establish team of AI experts in charge of overseeing the
process
Invest in AI literacy and training for HCP
Create AI-specific risk management protocols
Other
Graph 13- Distribution of the recommended steps to accelerate AI strategy in the medical field (Q23b) 
25 
 
4. Results analysis 
The following table summarizes all the variables that were tested for possible associations using 
the Chi-Square test. 
a df, degrees of freedom 
b ns, non-significant 
c The variable working country was dichotomized into “working in Portugal” or “working outside Portugal” 
d The main working sector was dichotomized into “public hospital” or “private hospital” 
  
Independent 
variable 
Dependent variable X2 (dfa) Significance 
Age 
AI use 0.052 (1) nsb 
Fear 2.511 (1) ns 
Positive attitude 0.906 (1) ns 
Knowledge about AI  
AI use 50.631 (1) p<0.001 
Fear 5.236 (1) p = 0.022 
Positive attitude 4.407 (1) p = 0.036 
Working countryc 
AI use 4.843 (1) p = 0.028 
Fear 1.843 (1) ns 
Positive attitude 9.285 (1) p = 0.002 
Main working sectord 
AI use 0.930 (1) ns  
Fear 0.095 (1) ns 
Positive attitude 0.020 (1) ns 
Table 4 - Summary of the results of associations between variables 
26 
 
4.1.Hypothesis testing 
Three different Chi-Square tests were performed to test our hypotheses. When a statistically 
significant result was achieved (p-value<0.05) the Phi-coefficient (Φ) was applied to measure 
the direction of the association between variables. Its value ranges from −1 to +1, “with negative 
numbers representing negative relationships, zero representing no relationship, and positive 
numbers representing positive relationships” (Allen, 2017). The results show that while H1 
should be rejected, H2 and H3 should not be rejected, as both of their p-values fall under 0.05. 
Table 5 summarizes our findings from the statistical tests. 
 
Table 5 - Hypotheses and results from the statistical tests 
Research 
Questions 
Hypotheses Results 
RQ2 
H1: A neuroradiologist’s use of 
AI is influenced by his/her age. 
X2 = 0.052 (p = 0.820) 
 
Therefore, H1 is rejected (p-value > 0.05). 
According to this sample, there is no association 
between a neuroradiologist’s age and his/her use of 
AI. 
H0: A neuroradiologist’s use of 
AI is independent of his/her age 
RQ3 
H2: A positive attitude towards 
the use of AI is influenced by 
previous knowledge about AI.  
X2 = 4.407 (p = 0.036) 
Φ = 0.155 
 
Therefore, H2 is not rejected (p-value <0.05). 
According to our sample, there appears to be a 
positive association (Phi>0) between knowledge 
about AI and having a positive attitude towards its 
use. 
H0: A positive attitude towards 
the use of AI is independent of 
previous knowledge about AI. 
H3: The fear of AI is influenced 
by previous knowledge about AI 
X2 = 5.236 (p = 0.022) 
Φ = -0.169  
 
Therefore, H3 is not rejected (p-value <0.05). 
According to this sample, there appears to be a 
negative relationship (Phi<0) between knowledge 
about AI and fear towards its use, with those 
knowing more about AI having less fear of its 
application in healthcare. 
H0: The fear of AI is independent 
of previous knowledge about AI 
27 
 
5. Discussion 
RQ1: What are the perceptions and perspectives of neuroradiologists towards the use of AI in 
their clinical practice? 
From the perceptions block, we can see that the questions related to PE were the ones with the 
highest agreement rates. This is in line with previous studies (Coppola et al., 2021; Waymel et 
al., 2019) and it indicates that most neuroradiologists acknowledge the augmenting abilities of 
AI tools. Moreover, only a small percentage of 27.0% agreed that working with AI requires 
more effort than working without AI. This is important information, as it indicates that EE is 
probably low among neuroradiologists, even for those who aren’t accustomed to using AI tools.  
Regarding facilitating conditions, results show mixed feelings about organizational readiness 
from neuroradiologists’ perspectives. Previous studies investigated the factors building up to 
AI-readiness at firm-level and many authors apply the Technology-Organizations-Environment 
(TOE) framework, which divides the determinants into 3 categories: technological, 
organizational and environmental  (AlSheibani et al., 2018; Jöhnk et al., 2021; Vasiljeva et al., 
2021).   
For the scope of our research, we will only comment on the organizational factors. In this 
category, Vasiljeva et al. (2021) focused on department readiness in terms of infrastructure, 
resources, and skills, as well as upper management support, which are the most relatable factors 
with Q14-Q15 on FC. The low agreement rates on both questions might indicate low 
implementation of AI technologies and or inadequate organizational readiness, not only in IT 
readiness but also from the lack of support by top management. Unfortunately, the lack of 
additional or open-ended questions on this topic prevented us from further exploring. 
Only a minority of 5.9% in the sample admitted feeling pressured into using AI. Even though 
feeling pressured may not be the most accurate representation of SI, the fact that 25.0% of the 
sample strongly disagreed (the highest response rate from all the questions) and that 47.3% 
disagreed may indicate a lack of social incentives, such as being surrounded by colleagues 
working with AI, or having an institution which actively encourages its use.  
This explanation is consistent with the results obtained with FC, as well as the low AI use rate 
found among the sample (51.6% of the respondents are not using AI tools). It is also worth 
mentioning that similar low AI use rates were found in the study by the European Society of 
28 
 
Radiology (2019), where 321 out of 675 radiologists (47.6%) mentioned that they were not 
using AI applications in clinical practice. However, our results were slightly higher than the 
ones obtained from Waymel et al. (2019), where 68.5% of the participant radiologists reported 
not using AI in their clinical practice, nor foreseeing any changes in the following year.  
There are two things worth mentioning in our results for AI use. First, the hetero-evaluation 
question might not have been the best way to test knowledge on a basic definition. Indeed, ML 
is a basic concept in AI. However, as there is still missing a universal definition for AI, 
neuroradiologists with some knowledge on the topic might have failed to recognize the correct 
answer. Also, it is possible that more neuroradiologists are already using AI tools but did not 
recognize so (Shinners et al., 2020). 
For perspectives, the results obtained were generally optimistic, with excitement and motivation 
being the two most voted emotions towards an AI-augmented scenario. A large share of 
neuroradiologists predicted an AI-based diagnosis reality in up to 10 years, which is similar to 
the forecast results obtained by Coppola et al. (2021) when asking radiologists about the 
expected time for AI to impact their profession (half the sample voted for 5-10 years and 20.3% 
voted for 10-20 years).  
Interestingly, about half the sample (52.2%) agreed that neuroradiologists who use AI are likely 
to replace neuroradiologists that don’t. Comparing this result with the ones got from fear of 
replacement by AI, which were significantly lower (Coppola et al., 2021; Huisman et al., 2021) 
one can say that the need for keeping up with innovation and its integration into clinical practice 
is already a trend in neuroradiology. 
Moving on to concerns, the main anticipated issues related to technological malfunctions 
(78.8%), lack of regulation (51.1%), and ethical issues (39.1%), while lower reputation was one 
of the least voted concerns, in contrast to the study by Coppola et al. (2021). These insights are 
indicative of the uncertainty and mistrust that still exist in the medical field. Additionally, they 
emphasize the fact that transparency, as well as a robust legal framework, are key priorities in 
need of addressing that could substantially encourage AI adoption by physicians.        
Upgrading the current IT infrastructures was one of the top suggestions by participants. Indeed, 
digital transformation remains a big challenge in healthcare (Gopal et al., 2019) with words 
such as “slow, complex, and bureaucracy” often being used to describe the current state of 
digitalization (Deloitte, 2020). As more and more medical data is being produced, 
29 
 
interoperability becomes urgent to bridge the gap between potential meaningful information 
and the deployment of technologies that can actually use that data (Deloitte, 2020; Lehne et al., 
2019). 
Addressing gaps in digital literacy was also a highlighted recommendation, which is in line 
with previous studies (Huisman et al., 2021; Waymel et al., 2019), as with the rate of 
insufficient AI knowledge reported by our sample. Our results underline that AI training should 
be incorporated into the traditional medical curricula. Investing in AI training would certainly 
help build trust in AI, thus ensuring more confidence in deploying its technologies. Also, it 
would increase opportunities for doctors' inclusion in AI solutions development. 
Ultimately, it was encouraging to see that neuroradiologists recommend the involvement of 
healthcare professionals in AI solutions. In truth, the future of AI health solutions will likely 
depend on the ability of multidisciplinary efforts between innovators and end-users such as 
doctors to develop efficient tools that can fit smoothly into the workflow of clinical practice. 
 
RQ2:  Does the age of neuroradiologists influence their use of AI in clinical practice? 
The results for H1 indicate that the use of AI is independent of the age of neuroradiologists. 
According to existent literature, as age increases, consumers tend to have more difficulty in 
processing new information, which hinders the adaptation to new technologies (Morris & 
Venkatesh, 2000). In line with this information, a study on 356 German firms found that older 
workforces (smaller share of young employees) were negatively related to the probability of 
adopting new or improved technologies (Meyer, 2011).  Similarly, Huisman et al. (2021) found 
increasing age as a negative predictor for an open and proactive attitude towards AI. 
However, despite showing lower rates of technology adoption, older populations have never 
been more digital than today and, in some cases, even present similar technology use rates to 
adults under 65 years old (Pew Research Center, 2017). Moreover, recent statistics in the EU 
show that, from 2015 to 2020, the percentage of adults (16-74 years old) that used internet daily 
increased from 65% to 80% (Eurostat, 2021). 
On the other hand, our sample was mainly represented by participants under 44 years old and 
people above 45 years old were included in the older group category. Also, from the senior 
group, only a minority of 5.4% was above 65 years old, which is the traditionally recognized 
30 
 
indicator for defining an old person (United Nations, Department of Economic and Social 
Affairs, 2019).  
It is also known that 65-year-olds nowadays have a significantly higher life expectancy, health 
status, and socioeconomic conditions than before (United Nations, Department of Economic 
and Social Affairs, 2019). Moreover, 65-year-olds today were already exposed, to some extent, 
to different technologies. A report on how baby boomers (people born between 1946-1964) 
view and use technology emphasized their unique historical perspective. This generation “grew 
up with technology: they were in their teens to early 30s when the first IBM PCs and Apples 
appeared, and were the innovators and early adopters of that era” (Rogers, 2009, p.3). 
Therefore, we found two main reasons for the results obtained in H1. Firstly, our sample lacked 
a representative amount of older neuroradiologists, as it was unproportioned to younger 
participants. Such differences in age distribution might have resulted from less inclusive 
channels for survey sharing, such as email or LinkedIn. Also, in most EU countries, the 
retirement age is around 65 years old. Hence, there might not be as many neuroradiologists still 
in practice. 
The second reason is that the effect of age on technology adoption might not have the same 
impact in this age group as in older seniors, such as people in their 70s or 80s. This is supported 
by Friemel (2016), who studied the digital divide among people above 65 years old. In his 
study, the author reported on data about internet use in Switzerland (1997–2013) to which he 
concluded that the major gap was not between the “pre-seniors” (50-59 years) and younger 
categories, but between the “old seniors” (70+) and the rest of the population. (Friemel, 2016).  
Age remains a relevant factor for technology acceptance and adoption. Previous studies on 
predictors of technology acceptance in older adults have shown the importance of computer 
knowledge, as well as tutorial support on the acceptance outcomes (Holzinger & Miesenberger, 
2009; Lee et al., 2011). As such, when making managerial decisions such as embarking on an 
AI strategy, managers should take into account the age of their target group, as the difficulty in 
adapting to new environments might differ according to age range. 
  
31 
 
RQ3: What is the impact of specific-AI knowledge of neuroradiologists on their predisposition 
towards its use? 
In our sample, 42.9% of participants rated their knowledge about AI as either insufficient or 
very insufficient. Similar results were achieved in previous studies (Castagno & Khalifa, 2020; 
Waymel et al., 2019), and they pose an issue related to an AI literacy gap. Indeed, despite the 
consensual opinion concerning the importance of integrating AI training in the medical 
curricula, there seems to be a translation gap as medical schools struggle to plan and implement 
these changes (Grunhut et al., 2021). 
This is particularly concerning if we take into account our findings in H2 and H3, which were 
both statistically significant. AI-related knowledge appears to influence the predisposition 
towards its use. On one hand, the knowledge about AI seems to be positively related to having 
an optimistic attitude towards its use, which is relevant, as people with a positive attitude are 
more likely to engage in AI adoption (Lichtenthaler, 2020; Wang et al., 2021). Also, according 
to the Diffusion of Innovations Theory, early adopters are crucial for driving a change in their 
working environment, as they will serve as pioneers for speeding the diffusion process among 
their peers (Rogers, 1983).      
On the other hand, there appears to be a negative relationship between knowledge about AI and 
fear of AI, with those knowing more about AI having less fear towards its application in 
healthcare. Huisman et al. (2021) also found that limited AI-specific knowledge among 
radiologists appeared to be associated with fear, while an intermediate to advanced knowledge 
about AI was associated with a positive attitude towards AI. 
In previous literature, the concept of “AI anxiety” has been used to discuss the fear and 
apprehension shown about “out of control AI” (Johnson & Verdicchio, 2017). A deeper look 
into the underlying sources of AI anxiety revealed contributing factors such as privacy violation 
anxiety, job replacement anxiety, learning anxiety, ethics violation anxiety, and lack of 
transparency anxiety, among others (Li & Huang, 2020). Indeed, in our research, the most stated 
concerns regarding AI indicate that neuroradiologists fear for patients’ safety, not only in 
medical terms (making a wrong decision based on an AI error) but also from an ethical 
perspective of data privacy.   
  
32 
 
6. Implications and Recommendations 
 Artificial Intelligence is shaping the future of healthcare. Doctors and other health 
professionals are part of this (r)evolution, not only as end-users but also as disseminators 
of trust in these new technologies and empowering patients in using them. 
 
 As the population ages, neurological disorders will spread, increasing pressure on the 
demand for efficient and cost-effective care. In neuroradiology, AI can play an 
important role in augmenting medical care and assisting health professionals in 
monitoring, diagnosing, and treating patients in an increasing health burden population. 
 
 Doctors and innovators such as start-ups must work together in producing efficient AI 
tools that fit seamlessly into the workflows. An example of collaboration could be 
applied to pilot tests to measure the outcomes of AI tools and foster the improvement 
of solutions from medical feedback. 
 
 Health institutions should integrate AI into their strategy and foster a working culture 
more prone to AI awareness, as it would encourage the involvement of all stakeholders 
in adoption behavior. Additionally, organizations should invest in adequate IT 
infrastructures and provide health professionals with opportunities to increase their AI 
literacy and skills (training sessions, seminars, etc.). 
 
 Medical schools will have to adapt their curricula to prepare future doctors in AI by 
developing knowledge, attitudes, and skills associated with clinical AI and critical 
judgment of its applicability, thus shaping AI competent doctors. Dedicated courses, 
practical activities, and contact with experts in the field are some of the ways in which 
awareness and overall attitudes could be improved. 
 
 Governments and policymakers should continue to work on a robust legal framework 
for AI regulation as it will increase trust and boost readiness for both organizations and 
health professionals. 
  
33 
 
7. Limitations and Future Research 
Despite the efforts made in the survey distribution via different platforms, only 255 responses 
were obtained. However, over 184 complete responses were used for the analysis, which 
represents a good proportion and created a consistent sample. This was unexpected considering 
the very specific professional background and the COVID-19 pandemic work overload in the 
sector.  
To assess the overall perceptions and perspectives on a topic that is not very familiar to some 
respondents could have led to some biased responses. To mitigate this risk simple questions 
were used, some of which included concrete examples to allow doctors less familiarized with 
AI to engage with the survey.  
The quantitative nature of the study design prevented further exploration of the nuances and 
reasons behind some answers. This can be continued in future research now that this baseline 
has been created. Findings from this study can be relevant for future research using a qualitative 
methodology (with interviews, focus groups, or participant observation), contributing to an 
enhanced understanding of current and future trends in neuroradiology as they intersect with 
AI.  
For future research, it would be interesting to explore the organizational context of participants, 
such as replicating this study in settings where AI tools are available in clinical practice. This 
would allow a better understanding of the rate of neuroradiologists rejecting AI by choice versus 
due to lack of opportunity. Additionally, it would be relevant to compare the perceptions and 
acceptance of doctors that have AI technologies available for use and the ones that don’t. Such 
research could provide insights to help diffuse innovation, as the good examples of AI adoption 
could serve as pioneers for institutions willing to innovate in AI.  
34 
 
8. Conclusions 
While there is excitement around the use of AI in Neuroradiology, its integration into clinical 
practice is still at an early stage, with some implementation challenges on the horizon.  
Health professionals are at the core of this transformation and, as such, will need to adapt to 
new roles. According to our findings, improving knowledge of AI will probably reduce the fear 
associated with it and encourage a positive attitude towards its use. Investing in AI literacy of 
health professionals will add knowledge and contribute to enhancing skills required and 
consequently encourage their early involvement in the development and/or usage of intelligent 
solutions.  
Neuroradiologists acknowledge the abilities of AI tools to improve their work and are willing 
to participate in an AI strategy. However, reassurance through providing the explanation and 
validation of new technologies, suitable working conditions, and the creation of a robust legal 
framework is still needed to raise trust, encouragement, and readiness. 
This research contributes to a better representation and understanding of neuroradiologists' 
perceptions and perspectives regarding the adoption of AI in clinical practice. Moreover, its 
findings can support organizational decision-making and present new viewpoints on the best 
practices for a successful transition into AI implementation. The employment of questions 
based on technology acceptance models sheds light on neuroradiologists' perspectives on their 
institutional context. Also, they provided a starting point for further investigation, in this 
specialist domain but also in that of other medical and even non-medical healthcare 
professionals. 
AI is seen to hold significant potential in Neuroradiology. This may be true of other fields in 
medicine. Increasing diagnostic accuracy, improving workflow efficiency, and cutting back on 
time-consuming tasks, are just a few ways AI will likely augment neuroradiologists' work 
productivity. For this transformation to happen, however, all stakeholders need to be involved 
under a clear AI strategy that focuses on improving the overall efficiency of their services, in a 
way that adds value not only to healthcare staff but also to patients.  
35 
 
Bibliography 
Accenture. (2017). Artificial Intelligence: Healthcare’s New Nervous System. Retrieved from 
https://www.accenture.com/us-en/insight-artificial-intelligence-future-growth 
Agrawal, A., Gans, J., & Goldfarb, A. (2018). Prediction machines: the simple economics of 
artificial intelligence. Harvard Business Press. 
Allen, B., Seltzer, S. E., Langlotz, C. P., Dreyer, K. P., Summers, R. M., Petrick, N., … 
Kandarpa, K. (2019). A Road Map for Translational Research on Artificial Intelligence in 
Medical Imaging: From the 2018 National Institutes of Health/RSNA/ACR/The Academy 
Workshop. Journal of the American College of Radiology, 16(9), 1179–1189. 
https://doi.org/10.1016/j.jacr.2019.04.014 
Allen, M. (2017). The SAGE Encyclopedia of Communication Research Methods. Thousand 
Oaks, California. https://doi.org/10.4135/9781483381411 NV  - 4 
AlSheibani, S., Cheung, Y., & Messom, C. (2018). Artificial intelligence adoption: AI-
readiness at firm-level. Paper present at the 22nd Pacific Asia Conference on Information 
Systems-Opportunities and Challenges for the Digitized Society: Are We Ready? (PACIS 
2018). In Proceedings of the 22nd Pacific Asia Conference on Information Systems - 
Opportunities and Challenges for the Digitized Society: Are We Ready?, PACIS 2018. 
Yokohama, Japan. 
Arani, L. A., Hosseini, A., Asadi, F., Masoud, S. A., & Nazemi, E. (2018). Intelligent computer 
systems for multiple sclerosis diagnosis: A systematic review of reasoning techniques and 
methods. Acta Informatica Medica, 26(4), 258–264. 
https://doi.org/10.5455/aim.2018.26.258-264 
Beadnall, H. N., Wang, C., Van Hecke, W., Ribbens, A., Billiet, T., & Barnett, M. H. (2019). 
Comparing longitudinal brain atrophy measurement techniques in a real-world multiple 
sclerosis clinical practice cohort: towards clinical integration? Therapeutic Advances in 
Neurological Disorders, 12, 1756286418823462. 
https://doi.org/10.1177/1756286418823462 
Bluemke, D. (2018). Radiology in 2018: Are you working or being replaced by AI? Radiology, 
287(2), 365–366. https://doi.org/10.1093/annonc/mdx781 
Castagno, S., & Khalifa, M. (2020). Perceptions of Artificial Intelligence Among Healthcare 
Staff: A Qualitative Survey Study. Frontiers in Artificial Intelligence, 3(October), 1–7. 
https://doi.org/10.3389/frai.2020.578983 
Chartrand, G., Cheng, P. M., Vorontsov, E., Drozdzal, M., Turcotte, S., Pal, C. J., … Tang, A. 
(2017). Deep learning: A primer for radiologists. Radiographics, 37(7), 2113–2131. 
https://doi.org/10.1148/rg.2017170077 
Choy, G., Khalilzadeh, O., Michalski, M., Do, S., Samir, A. E., Pianykh, O. S., … Dreyer, K. 
J. (2018). Current applications and future impact of machine learning in radiology. 
Radiology, 288(2), 318–328. https://doi.org/10.1148/radiol.2018171820 
Coppola, F., Faggioni, L., Regge, D., Giovagnoni, A., Golfieri, R., Bibbolino, C., … Grassi, R. 
(2021). Artificial intelligence: radiologists’ expectations and opinions gleaned from a 
nationwide online survey. Radiologia Medica, 126(1), 63–71. 
https://doi.org/10.1007/s11547-020-01205-y 
Davenport, T., & Kalakota, R. (2019). The Potential for Artificial Intelligence in Healthcare. 
36 
 
Future Healthcare Journal, 6(2), 94–98. https://doi.org/10.2139/ssrn.3525037 
Davis, F. D. (1989). Perceived usefulness, perceived ease of use, and user acceptance of 
information technology. MIS Quarterly: Management Information Systems, 13(3), 319–
339. https://doi.org/10.2307/249008 
Deloitte. (2020). Digital transformation Shaping the future of European healthcare. Deloitte 
Centre for Health Solutions. Retrieved from 
https://www2.deloitte.com/content/dam/Deloitte/nl/Documents/public-sector/deloitte-nl-
shaping-the-future-of-european-healthcare.pdf 
Doraiswamy, P. M., Blease, C., & Bodner, K. (2020). Artificial intelligence and the future of 
psychiatry: Insights from a global physician survey. Artificial Intelligence in Medicine, 
102, 101753. https://doi.org/10.1016/j.artmed.2019.101753 
Esmaeilzadeh, P. (2020). Use of AI-based tools for healthcare purposes : a survey study from 
consumers ’ perspectives. BMC Medical Informatics and Decision Making, 20(170). 
European Commission. (n.d.). Non-communicable diseases. Retrieved from 
https://ec.europa.eu/health/non-communicable-diseases/overview_en#latest-updates 
European Commission. (2018). Artificial Intelligence for Europe. COM (2018) 237 Final. 
European Society of Radiology. (2019). Impact of artificial intelligence on radiology: a 
EuroAIM survey among members of the European Society of Radiology. Insights into 
Imaging, 10(1), 1–11. https://doi.org/10.1186/s13244-019-0798-3 
Eurostat. (2021). Daily internet users, 2020. Retrieved from 
https://ec.europa.eu/eurostat/web/products-eurostat-news/-/edn-20211008-1 
Feigin, V. L., Nichols, E., Alam, T., Bannick, M. S., Beghi, E., Blake, N., … Vos, T. (2019). 
Global, regional, and national burden of neurological disorders, 1990–2016: a systematic 
analysis for the Global Burden of Disease Study 2016. The Lancet Neurology, 18(5), 459–
480. https://doi.org/10.1016/S1474-4422(18)30499-X 
Food and Drug Administration. (2018). Medical Imaging. Retrieved from 
https://www.fda.gov/radiation-emitting-products/radiation-emitting-products-and-
procedures/medical-imaging 
Franke, T. M., Ho, T., & Christie, C. A. (2012). The Chi-Square Test: Often Used and More 
Often Misinterpreted. American Journal of Evaluation, 33(3), 448–458. 
https://doi.org/10.1177/1098214011426594 
Friemel, T. N. (2016). The digital divide has grown old: Determinants of a digital divide among 
seniors. New Media and Society, 18(2), 313–331. 
https://doi.org/10.1177/1461444814538648 
Gopal, G., Suter-Crazzolara, C., Toldo, L., & Eberhardt, W. (2019). Digital transformation in 
healthcare - Architectures of present and future information technologies. Clinical 
Chemistry and Laboratory Medicine, 57(3), 328–335. https://doi.org/10.1515/cclm-2018-
0658 
Grunhut, J., Wyatt, A. T., & Marques, O. (2021). Educating Future Physicians in Artificial 
Intelligence (AI): An Integrative Review and Proposed Changes. Journal of Medical 
Education and Curricular Development, 0, 1–8. 
https://doi.org/10.1177/23821205211036836 
37 
 
Gursoy, D., Chi, O. H., Lu, L., & Nunkoo, R. (2019). Consumers acceptance of artificially 
intelligent (AI) device use in service delivery. International Journal of Information 
Management, 49(March), 157–169. https://doi.org/10.1016/j.ijinfomgt.2019.03.008 
He, J., Baxter, S. L., Xu, J., Xu, J., Zhou, X., & Zhang, K. (2019). The practical implementation 
of artificial intelligence technologies in medicine. Nature Medicine, 25(1), 30–36. 
https://doi.org/10.1038/s41591-018-0307-0 
Herweh, C., Ringleb, P. A., Rauch, G., Gerry, S., Behrens, L., Möhlenbruch, M., … Nagel, S. 
(2016). Performance of e-ASPECTS software in comparison to that of stroke physicians 
on assessing CT scans of acute ischemic stroke patients. International Journal of Stroke, 
11(4), 438–445. https://doi.org/10.1177/1747493016632244 
Holzinger, A., & Miesenberger, K. (2009). Which factors form older adults’ acceptance of 
mobile information and communication technologies? In Symposium of the Austrian HCI 
and Usability Engineering Group. Springer Berlin Heidelberg. 
https://doi.org/10.1007/978-3-642-10308-7 
Huisman, M., Ranschaert, E., Parker, W., Mastrodicasa, D., Koci, M., Pinto de Santos, D., … 
Willemink, M. J. (2021). An international survey on AI in radiology in 1,041 radiologists 
and radiology residents part 1: fear of replacement, knowledge, and attitude. European 
Radiology, 31(9), 7058–7066. https://doi.org/10.1007/s00330-021-07781-5 
Institute of Medicine. (2001). Crossing the Quality Chasm: A New Health System for the 21st 
Century. Washington, DC: The National Academies Press. https://doi.org/10.17226/10027 
Jha, S., & Topol, E. J. (2016). Adapting to artificial intelligence: Radiologists and pathologists 
as information specialists. JAMA - Journal of the American Medical Association, 316(22), 
2353–2354. https://doi.org/10.1001/jama.2016.17438 
Jiang, F., Jiang, Y., Zhi, H., Dong, Y., Li, H., Ma, S., … Wang, Y. (2017). Artificial intelligence 
in healthcare: Past, present and future. Stroke and Vascular Neurology, 2(4), 230–243. 
https://doi.org/10.1136/svn-2017-000101 
Jöhnk, J., Weißert, M., & Wyrtki, K. (2021). Ready or Not, AI Comes— An Interview Study 
of Organizational AI Readiness Factors. Business & Information Systems Engineering, 
63(1), 5–20. https://doi.org/10.1007/s12599-020-00676-7 
Johnson, D., & Verdicchio, M. (2017). AI Anxiety. Journal of the American Society for 
Information Science and Technology, 68(9), 2267–2270. https://doi.org/10.1002/asi 
Kaka, H., Zhang, E., & Khan, N. (2021). Artificial Intelligence and Deep Learning in 
Neuroradiology: Exploring the New Frontier. Canadian Association of Radiologists 
Journal, 72(1), 35–44. https://doi.org/10.1177/0846537120954293 
Kaplan, A., & Haenlein, M. (2019). Siri, Siri, in my hand: Who’s the fairest in the land? On the 
interpretations, illustrations, and implications of artificial intelligence. Business Horizons, 
62(1), 15–25. https://doi.org/10.1016/j.bushor.2018.08.004 
King, W. R., & He, J. (2006). A meta-analysis of the technology acceptance model. Information 
and Management, 43(6), 740–755. https://doi.org/10.1016/j.im.2006.05.003 
Krittanawong, C., Zhang, H. J., Wang, Z., Aydar, M., & Kitai, T. (2017). Artificial Intelligence 
in Precision Cardiovascular Medicine. Journal of the American College of Cardiology, 
69(21), 2657–2664. https://doi.org/10.1016/j.jacc.2017.03.571 
38 
 
Kulkarni, S., Seneviratne, N., Baig, M. S., & Khan, A. H. A. (2020). Artificial Intelligence in 
Medicine: Where Are We Now? Academic Radiology, 27(1), 62–70. 
https://doi.org/10.1016/j.acra.2019.10.001 
Lapointe, L., & Rivard, S. (2006). Getting physicians to accept new information technology: 
insights from case studies. Cmaj, 174(11), 1573–1578. 
Lee, B., Chen, Y., & Hewitt, L. (2011). Age differences in constraints encountered by seniors 
in their use of computers and the internet. Computers in Human Behavior, 27(3), 1231–
1237. https://doi.org/10.1016/j.chb.2011.01.003 
Lehne, M., Sass, J., Essenwanger, A., Schepers, J., & Thun, S. (2019). Why digital medicine 
depends on interoperability. Npj Digital Medicine, 2(1), 1–5. 
https://doi.org/10.1038/s41746-019-0158-1 
Li, J., & Huang, J. S. (2020). Dimensions of artificial intelligence anxiety based on the 
integrated fear acquisition theory. Technology in Society, 63(October). 
https://doi.org/10.1016/j.techsoc.2020.101410 
Lichtenthaler, U. (2020). Extremes of acceptance: employee attitudes toward artificial 
intelligence. Journal of Business Strategy, 41(5), 39–45. https://doi.org/10.1108/JBS-12-
2018-0204 
Liew, C. (2018). The future of radiology augmented with Artificial Intelligence : A strategy for 
success. European Journal of Radiology, 102(March), 152–156. 
https://doi.org/10.1016/j.ejrad.2018.03.019 
Lima, A. A., Mridha, M. F., Das, S. C., Kabir, M. M., Islam, M. R., & Watanobe, Y. (2022). A 
Comprehensive Survey on the Detection, Classification, and Challenges of Neurological 
Disorders. Biology, 11(3), 469. https://doi.org/10.3390/BIOLOGY11030469 
Liu, X., Chen, K., Wu, T., Weidman, D., Lure, F., & Li, J. (2018). Use of multimodality 
imaging and artificial intelligence for diagnosis and prognosis of early stages of 
Alzheimer’s disease. Translational Research, 194, 56–67. 
https://doi.org/10.1016/j.trsl.2018.01.001 
Loomis, G. A., Ries, S. J., Saywell, R. M., & Thakker, N. R. (2002). If electronic medical 
records are so great, why aren’t family physicians using them? Journal of Family Practice, 
51(7), 636–641. 
Mckinsey. (2020). Transforming healthcare with AI: The impact on the workforce and 
organizations. Retrieved from https://www.mckinsey.com/industries/healthcare-systems-
and-services/our-insights/transforming-healthcare-with-ai 
Mellinger, C. D., & Hanson, T. A. (2017). Quantitative Research Methods in Translation and 
Interpreting Studies. Routledge. 
Meyer, J. (2011). Workforce age and technology adoption in small and medium-sized service 
firms. Small Business Economics, 37, 305–324. https://doi.org/10.1007/s11187-009-9246-
y 
Middei, S. (2022). Neuroimaging Applications for Diagnosis and Therapy of Pathologies in the 
Central and Peripheral Nervous System. Brain Sciences, 12(2), 1–5. 
https://doi.org/10.3390/brainsci12020207 
Morris, M. G., & Venkatesh, V. (2000). Age differences in technology adoption decisions: 
39 
 
Implications for a changing work force. Personnel Psychology, 53(2), 375–403. 
https://doi.org/10.1111/j.1744-6570.2000.tb00206.x 
Neiman Institute. (2012). Report Medical Imaging : Is the Growth Boom Over ? Neiman Report 
Brief 1. 
Noguerol, T. M., Paulano-godino, F., Martín-valdivia, M. T., Menias, C. O., & Luna, A. (2019). 
Strengths , Weaknesses , Opportunities , and Threats Analysis of Artificial Intelligence 
and Machine Learning Applications in Radiology. Journal of the American College of 
Radiology, 16(9), 1239–1247. https://doi.org/10.1016/j.jacr.2019.05.047 
OECD. (2017). Health at a Glance 2017: OECD Indicators. Paris: OECD Publishing. 
Oh, S., Kim, J. H., Choi, S. W., Lee, H. J., Hong, J., & Kwon, S. H. (2019). Physician 
confidence in artificial intelligence: An online mobile survey. Journal of Medical Internet 
Research, 21(3). https://doi.org/10.2196/12422 
Olthof, A. W., Ooijen, P. M. A. Van, & Mehrizi, M. H. R. (2020). Promises of artificial 
intelligence in neuroradiology : a systematic technographic review. Neuroradiology, 
62(10), 1265–1278. 
Pesapane, F., Codari, M., & Sardanelli, F. (2018). Artificial intelligence in medical imaging: 
threat or opportunity? Radiologists again at the forefront of innovation in medicine. 
European Radiology Experimental, 2(1). https://doi.org/10.1186/s41747-018-0061-6 
Pew Research Center. (2017). Tech Adoption Climbs Among Older Adults. Pew Research 
Center. Retrieved from http://www.pewinternet.org/2017/05/17/technology-use-among-
seniors/ 
PWC. (2017). Sherlock in Health: How artificial intelligence may improve quality and 
efficiency , whilst reducing healthcare costs in Europe. Sherlock in Health: How artificial 
intelligence may improve quality and efficiency , whilst reducing healthcare costs in 
Europe. Retrieved from https://www.pwc.com.tr/en/sektorler/saglik/yayinlar/sherlock-
saglik-sektorunu-arastiriyor.html 
Ramesh, A. N., Kambhampati, C., Monson, J. R. T., & Drew, P. J. (2004). Artificial intelligence 
in medicine. Annals of the Royal College of Surgeons of England, 86(5), 334–338. 
https://doi.org/10.1308/147870804290 
Rogers, E. M. (1983). Diffusion of innovations. Diffusion of Innovations (3rd editio). New 
York: The Free Press. https://doi.org/10.4324/9780203710753-35 
Rogers, M. (2009). Boomers and Technology: An Extended Conversation. World Future 
Review. Retrieved from 
file:///C:/Users/Leonor/Downloads/2009_boomers_and_technology_final_report.pdf 
Rong, G., Mendez, A., Bou Assi, E., Zhao, B., & Sawan, M. (2020). Artificial Intelligence in 
Healthcare: Review and Prediction Case Studies. Engineering, 6(3), 291–301. 
https://doi.org/10.1016/j.eng.2019.08.015 
Sailer, A. M., Van Zwam, W. H., Wildberger, J. E., & Grutters, J. P. C. (2015). Cost-
effectiveness modelling in diagnostic imaging: a stepwise approach. European Radiology, 
25, 3629–3637. https://doi.org/10.1007/s00330-015-3770-8 
Sampieri, R. H., Collado, C. H., & Lucio, P. B. (2012). Metodologia de Pesquisa (3. ed). São 
Paulo: McGraw-Hill. 
40 
 
Sarwar, S., Dent, A., Faust, K., Richer, M., Djuric, U., Ommeren, R. Van, & Diamandis, P. 
(2019). Physician perspectives on integration of artificial intelligence into diagnostic 
pathology. Npj Digital Medicine, 2(1), 1–7. https://doi.org/10.1038/s41746-019-0106-0 
Schwartz, W. B. (1970). Medicine and the computer: the promise and problems of change. The 
New England Journal of Medicine, 253(23), 1257–1264. 
Shaw, J., Rudzicz, F., Jamieson, T., & Goldfarb, A. (2019). Artificial Intelligence and the 
Implementation Challenge. Journal of Medical Internet Research, 21(7). 
https://doi.org/10.2196/13659 
Shinners, L., Aggar, C., Grace, S., & Smith, S. (2020). Exploring healthcare professionals’ 
understanding and experiences of artificial intelligence technology use in the delivery of 
healthcare: An integrative review. Health Informatics Journal, 26(2), 1225–1236. 
https://doi.org/10.1177/1460458219874641 
Siuly, S., & Zhang, Y. (2016). Medical Big Data: Neurological Diseases Diagnosis Through 
Medical Data Analysis. Data Science and Engineering, 1(2), 54–64. 
https://doi.org/10.1007/s41019-016-0011-3 
Szolovits, P. (2019). Artificial Intelligence in Medicine. Routledge. 
Tang, F. hay, Ng, D. K. ., & Chow, D. H. K. (2011). An image feature approach for computer-
aided detection of ischemic stroke. Computers in Biology and Medicine, 41(7), 529–536. 
https://doi.org/10.1016/j.compbiomed.2011.05.001 
Tasdogan, A. M. (2020). Knowledge, Attitudes and Perspectives of Anesthesiologists on 
Artificial Intelligence. Eurasian Journal of Medical Investigation, 4(1), 1–6. 
https://doi.org/10.14744/ejmi.2020.54709 
Tolosa, E., Garrido, A., Scholz, S. W., & Poewe, W. (2021). Challenges in the diagnosis of 
Parkinson’s disease. The Lancet Neurology, 20(5), 385–397. 
https://doi.org/10.1016/S1474-4422(21)00030-2 
United Nations, Department of Economic and Social Affairs, P. D. (2019). World Population 
Ageing 2019: Highlights. World Population Ageing 2019. Retrieved from 
http://link.springer.com/chapter/10.1007/978-94-007-5204-7_6 
Vaishya, R., Javaid, M., Khan, I. H., & Haleem, A. (2020). Artificial Intelligence (AI) 
applications for COVID-19 pandemic. Diabetes and Metabolic Syndrome: Clinical 
Research and Reviews, 14(4), 337–339. https://doi.org/10.1016/j.dsx.2020.04.012 
Vasiljeva, T., Kreituss, I., & Lulle, I. (2021). Artificial Intelligence: The Attitude of the Public 
and Representatives of Various Industries. Journal of Risk and Financial Management, 
14(8), 339. https://doi.org/10.3390/jrfm14080339 
Venkatesh, V., & Davis, F. D. (2000). A Theoretical Extension of the Technology Acceptance 
Model: Four Longitudinal Field Studies. Management Science, 46(2), 186–204. Retrieved 
from https://www.jstor.org/stable/pdf/2634758.pdf 
Venkatesh, V., Morris, M. G., Davis, G. B., & Davis, F. D. (2003). User Acceptance of 
Information Technology: toward a unified view. MIS Quarterly: Management Information 
Systems, 27(3), 425–478. 
Wang, W., Chen, L., Xiong, M., & Wang, Y. (2021). Accelerating AI Adoption with 
Responsible AI Signals and Employee Engagement Mechanisms in Health Care. 
41 
 
Information Systems Frontiers. https://doi.org/10.1007/s10796-021-10154-4 
Waymel, Q., Badr, S., Demondion, X., Cotten, A., & Jacques, T. (2019). Impact of the rise of 
artificial intelligence in radiology: What do radiologists think? Diagnostic and 
Interventional Imaging, 100(6), 327–336. https://doi.org/10.1016/j.diii.2019.03.015 
World Health Organization. (2006). Neurological disorders: Public health challenges. 
https://doi.org/10.1001/archneur.1997.00550190066016 
World Health Organization. (2016). Mental health: neurological disorders. Retrieved from 
https://www.who.int/news-room/questions-and-answers/item/mental-health-
neurological-disorders 
Yao, A. D., Cheng, D. L., Pan, I., & Kitamura, F. (2020). Deep learning in neuroradiology: A 
systematic review of current algorithms and approaches for the new wave of imaging 
technology. Radiology: Artificial Intelligence, 2(2), e190026. 
https://doi.org/10.1148/RYAI.2020190026 
Yu, K., Beam, A. L., & Kohane, I. S. (2018). Artificial intelligence in healthcare. Nature 
Biomedical Engineering, 2(10), 719–731. https://doi.org/10.1038/s41551-018-0305-z 
Zaharchuk, G., Gong, E., Wintermark, M., Rubin, D., & Langlotz, C. P. (2018). Deep learning 
in neuroradiology. American Journal of Neuroradiology, 39(10), 1776–1784. 
https://doi.org/10.3174/ajnr.A5543 
  
42 
 
Appendix I – Email sent to contact societies of neuroradiology 
Dear Dr. X, 
My name is Leonor Monteiro. I am a portuguese student writing my master thesis in Business 
at Católica Lisbon School of Business and Economics (https://www.clsbe.lisboa.ucp.pt). My 
research focuses on the perceptions and projections of neuroradiologists regarding Artificial 
Intelligence (AI) in clinical practice. My work is under the supervision of Prof. Henrique 
Martins, an active researcher in Digital Health (https://www.henriquemartins.eu). 
I have developed an online survey with the help of experts in the field, and I am sending you 
the script in attachment. My goal is to reach out to as many neuroradiologists in Europe as 
possible. Therefore, I would like to ask for your help as President of Y: would you be so kind 
to share the link to this survey among the members of your association? I will gladly share the 
results with Y, as they can be in your interest. I am also including a small text, which I have 
shared with several contacts, as it may be helpful for sharing purposes. 
I look forward to hearing from you soon and will be available for any questions you might have 
via email or teams/zoom. Thank you for your attention. 
Best regards, 
Leonor Monteiro  
www.linkedin.com/in/leonor-líbano-monteiro  
 
Note: 
X – Last name of the president of the society 
Y – Name of the society of neuroradiology 
 
 
Appendix II – LinkedIn message to contact neuroradiologists 
Hello,  
I kindly invite you to participate in my MSc thesis study about the perceptions and projections 
of neuroradiologists regarding Artificial Intelligence in clinical practice: 
https://ucplbusiness.co1.qualtrics.com/jfe/form/SV_3Dd4s31iE1f2ahg  
Thank you in advance! 
Leonor 
 
43 
 
Appendix III – Survey script  
Dear participant, 
 
This study is part of my MSc thesis in Business at the Católica Lisbon School of Business and 
Economics. My research focuses on the perceptions and projections of neuroradiologists 
regarding Artificial Intelligence adoption in clinical practice.  
 
This is a multiple-choice survey and it should take no longer than 8 minutes to complete. Please 
choose the preferred language (portuguese or english) in the top right corner.  
 
I kindly ask you to carefully read through the questions and answer them honestly. All answers 
will be anonymous and used for research purposes only.  
 
Thank you for your participation!  
 
Leonor Líbano Monteiro 
 
Demographics 
Q1: Gender   
Female 
Male 
Rather not say 
 
Q2: Age 
25 – 34  
35 – 44 
45 – 54 
55 – 64 
≥ 65 
 
Q3: Where are you currently working? 
- 
 
Q4: What is your highest educational degree earned? 
Bachelor’s degree 
Master’s degree 
PhD 
 
Q5: What is your current professional situation? 
Specialist 
Intern attending the first 2 years of training 
Intern attending the last years of training  
44 
 
Q6: What is your main site of professional activity? 
Public hospital  
Private hospital 
Other 
 
Q7: Do you have any advanced specific background? (PhD, Research fellowship, etc.) 
Yes 
No 
 
AI knowledge 
Q8: According to the European Commission: “Artificial intelligence (AI) refers to systems 
that display intelligent behaviour by analysing their environment and taking actions – 
with some degree of autonomy – to achieve specific goals”. Based on this definition, how 
would you classify your knowledge about AI? 
 1 (Very insufficient) 2 (Insufficient) 3 (Sufficient) 4 (Good) 5 (Very good) 
 
Q9: How would you define "Machine Learning"? 
Choose only one option 
- It is the same as AI (i.e. they are synonyms) 
- Broader term that includes all AI technologies that can learn from data and recognize patterns 
- AI branch in which algorithms are trained to learn from data without explicit programming 
- Other 
 
Q10a: Do you use AI-based tools in your clinical practice? (e.g. a software that detects, 
quantifies or classifies a certain lesion based on medical imaging) 
Choose only one option 
- Yes 
- No 
- Not sure 
- Not that I am aware of 
 
If you answered “Yes” to the previous question: 
Q10b. How often do you use AI tools? 
- In all the cases that I work on  
- Everyday 
- Every week 
- Few times a month 
- Few times a year 
 
 
 
45 
 
Perceptions and attitudes towards AI 
Please rate your agreement with the following sentences: 
Q11: I think that AI tools improve diagnosis accuracy (i.e. decrease medical error) 
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q12: I think that AI tools accelerate some tasks thus improving time response to patients 
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q13: Working with AI tools requires more effort (e.g. time invested) than working 
without AI tools   
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q14: My institution promotes the use of AI in clinical practice 
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q15: My institution has the right conditions (good quality dataset, capable IT services, 
advanced digital solutions) to support AI adoption in clinical practice 
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q16: I feel pressured by my colleagues or institution to use AI in daily clinical practice  
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
Q17a: Please rate your agreement on the following sentence: 
There should be AI training in the medical curriculum (with an eventual reduction in 
education time dedicated to traditional medical training, if needed) 
1 (Strongly disagree) 2 (Disagree) 3 (Neither agree nor disagree) 4 (Agree) 5 (Strongly agree) 
 
If you answered “Agree” or “Strongly agree”: 
Q17b. How many hours of traditional medical training should be replaced by Ai training? 
- 10h 
- 20h 
-  40h 
- 70h  
-  >100h  
 
Q18: Which AI-related topic do you think is the most important to be taught in medical 
school? Choose only one option 
- Limitations and challenges 
- Understanding the construction of algorithms 
- Taking the lead in AI solutions development 
- Surviving the AI revolution 
- None 
- Other 
46 
 
Perspectives regarding AI 
Please watch this short video (50 sec) before answering the next questions 
https://www.youtube.com/embed/jZg5QhL3Ckc?rel=0&autoplay=1&start=130&end=17
8  
 
In this video we hear Dr. Eric Topol, an expert in digital medicine, saying that “many 
conditions could be AI-diagnosed”.  
Q19: When do you think this will become a reality? 
- In 2 years 
- In 4 years 
- In 6 years 
- In 10 years 
- In 15 or more years 
- Never  
 
Q20: How does this scenario make you feel? Choose up to 3 options 
- Afraid 
- Relieved 
- Indifferent 
- Excited 
- Motivated 
- Demotivated  
- Other 
 
Q21: How likely is it that neuroradiologists who use AI will replace neuroradiologists who 
don't? 
1 (Very unlikely) 2 (Unlikely) 3 (No opinion) 4 (Likely) 5 (Very likely)  
 
Q22: In this scenario of AI automation what would be your major concerns? (Choose up 
to 3 options) 
- Lower salaries and/or job opportunities 
- Lower reputation, as neuroradiologists would no longer perform certain tasks 
- Ethical issues related to patients’ data privacy and security 
- Threat to doctor-patient relationship 
- Regulatory concerns (e.g. lack of standard regulation, liability issues)  
- Technological concerns regarding AI malfunction (e.g. making a wrong decision based on a 
AI error) 
- Other 
 
 
47 
 
Q23a. Imagine the following situation: "You work in a hospital/institution and the 
Administration calls you to discuss about AI in the medical field" 
 
What are your initial thoughts? 
- I don't want to hear about this  
- I am too busy for IT stuff 
- I don't want to be replaced by AI, don't count with me 
- I want to be involved 
- I want to help push this process forward 
- Wow! I want to be ahead of the game, I am in! 
 
If you choose one of the last three options 
Q23b. Which of the following steps would you recommend to accelerate the process? 
Choose up to 3 options 
- Invest in AI literacy and training for healthcare professionals  
- Upgrade the current IT infrastructures for a better support to AI tools 
- Promote the collaboration of healthcare professionals in developing/improving AI solutions 
- Establish a multidisciplinary team of AI experts in charge of overseeing the process  
- Create specific protocols for risk management of AI-related problems 
- Other 
 
Thank you! This is not an AI-powered survey, but I am happy to provide more information 
about my research through s-mlpsmonteiro@ucp.pt (Leonor Monteiro)  
 
Q24: I may come to conduct interviews on this topic. If you are ok with being contacted for a 
zoom interview let me know your email 
  
48 
 
Appendix IV – Descriptive statistics 
Q1: Gender 
  Frequency Percentage 
Valid 
Female 68 37,0 
Male 115 62,5 
Rather 
not say 
1 0,5 
Total 184 100,0 
 
Q2: Age 
    Frequency Percentage 
Valid 
25 - 34 38 20,7 
35 - 44 70 38,0 
45 - 54 40 21,7 
55 - 64 26 14,1 
> 65 10 5,4 
Total 184 100,0 
 
Q3: Where are you currently working? 
  Frequency Percentage 
Austria 2 1,1 
Belgium 2 1,1 
Bosnia and Herzegovina 2 1,1 
Bulgaria 2 1,1 
Croatia 2 1,1 
Denmark 9 4,9 
Finland 1 0,5 
France 24 13,0 
Germany 21 11,4 
Greece 4 2,2 
Hungary 1 0,5 
Ireland 1 0,5 
Italy 18 9,8 
Netherlands 4 2,2 
Norway 2 1,1 
Poland 2 1,1 
Portugal 30 16,3 
49 
 
Romania 1 0,5 
Slovakia 1 0,5 
Slovenia 2 1,1 
Spain 21 11,4 
Sweden 1 0,5 
Switzerland 13 7,1 
Turkey 3 1,6 
UK 15 8,2 
Total 184 100,0 
 
Q4: What is your highest educational degree earned? 
 Frequency Percentage 
Bachelor's degree 29 15,8 
Master's degree 83 45,1 
PhD 72 39,1 
Total 184 100,0 
 
Q5: What is your current professional situation? 
 Frequency Percentage 
Specialist 165 89,7 
Intern attending the 
first 2 years of 
training 
10 5,4 
Intern attending the 
last years of training 
9 4,9 
Total 184 100,0 
 
Q6: What is your main site of professional activity? 
 Frequency Percentage 
Public hospital 143 77,7 
Private hospital 27 14,7 
Other 14 7,6 
Total 184 100,0 
 
 
50 
 
Q7: Do you have any advanced specific background? (PhD, 
Research fellowship, etc.) 
 Frequency Percentage 
Yes 86 46,7 
No 98 53,3 
Total 184 100,0 
 
Q8: According to the European Commission: “Artificial intelligence (AI) refers to 
systems that display intelligent behaviour by analysing their environment and taking 
actions – with some degree of autonomy – to achieve specific goals”. Based on this 
definition, how would you classify your knowledge about AI? 
 Frequency Percentage 
Very insufficient 11 6,0 
Insufficient 68 37,0 
Sufficient 67 36,4 
Good 33 17,9 
Very good 5 2,7 
Total 184 100,0 
 
Q9: How would you define "Machine Learning"? 
Choose only one option 
  Frequency Percentage 
It is the same as AI (i.e. they are 
synonyms) 
1 0,5 
Broader term that includes all AI 
technologies that can learn from data and 
recognize patterns 
77 41,8 
AI branch in which algorithms are trained 
to learn from data without explicit 
programming 
103 56,0 
Other 3 1,6 
Total 184 100,0 
 
51 
 
Q10a: Do you use AI-based tools in your clinical practice? (e.g. a software that detects, 
quantifies or classifies a certain lesion based on medical imaging) 
Choose only one option 
  Frequency Percentage 
Yes 89 48,4 
No 80 43,5 
Not sure 5 2,7 
Not that I am aware of 10 5,4 
Total 184 100,0 
 
Q10b. How often do you use AI tools? 
 Frequency Percentage 
Valid 
In every case that I 
work on 
2 1,1 
Everyday 32 17,4 
Every week 27 14,7 
Few times a month 22 12,0 
Few times a year 6 3,3 
Total 89 48,4 
Missing System 95 51,6 
Total 184 100,0 
 
Q11: I think that AI tools improve diagnosis accuracy (i.e. decrease 
medical error) 
 Frequency Percentage 
Strongly disagree 3 1,6 
Disagree 12 6,5 
Neither agree nor disagree 46 25,0 
Agree 97 52,7 
Strongly agree 26 14,1 
Total 184 100,0 
 
52 
 
Q12: I think that AI tools accelerate some tasks thus improving time 
response to patients 
 Frequency Percentage 
Strongly disagree 2 1,1 
Disagree 18 9,8 
Neither agree nor disagree 28 15,2 
Agree 110 59,8 
Strongly agree 26 14,1 
Total 184 100,0 
 
 
Q13: Working with AI tools requires more effort (e.g. time invested) 
than working without AI tools 
 Frequency Percentage 
Strongly disagree 5 2,7 
Disagree 68 37,0 
Neither agree nor disagree 61 33,2 
Agree 42 22,8 
Strongly agree 8 4,3 
Total 184 100,0 
 
Q14: My institution promotes the use of AI in clinical practice 
  Frequency Percentage 
Strongly disagree 28 15,2 
Disagree 29 15,8 
Neither agree nor disagree 69 37,5 
Agree 50 27,2 
Strongly agree 8 4,3 
Total 184 100,0 
 
 
53 
 
Q15: My institution has the right conditions (good quality dataset, 
capable IT services, advanced digital solutions) to support AI 
adoption in clinical practice 
 Frequency Percentage 
Strongly disagree 27 14,7 
Disagree 49 26,6 
Neither agree nor disagree 35 19,0 
Agree 69 37,5 
Strongly agree 4 2,2 
Total 184 100,0 
 
Q16: I feel pressured by my colleagues or institution to use AI in 
daily clinical practice 
 Frequency Percentage 
Strongly disagree 46 25,0 
Disagree 87 47,3 
Neither agree nor disagree 40 21,7 
Agree 10 5,4 
Strongly agree 1 0,5 
Total 184 100,0 
 
Q17a: Please rate your agreement on the following sentence: 
There should be AI training in the medical curriculum (with an eventual 
reduction in education time dedicated to traditional medical training, if needed) 
 Frequency Percentage 
Strongly disagree 3 1,6 
Disagree 30 16,3 
Neither agree nor disagree 41 22,3 
Agree 76 41,3 
Strongly agree 34 18,5 
Total 184 100,0 
 
54 
 
Q17b. How many hours of traditional medical training should be replaced by Ai 
training? 
 Frequency Percentage 
Valid 
10h 37 20,1 
20h 28 15,2 
40h 23 12,5 
70h 10 5,4 
> 100h 12 6,5 
Total 110 59,8 
Missing System 74 40,2 
Total 184 100,0 
 
Q18: Which AI-related topic do you think is the most important to be taught in 
medical school? Choose only one option 
 Frequency Percentage 
Limitations and challenges 87 47,3 
Understanding the construction of algorithms 40 21,7 
Taking the lead in AI solutions development 35 19,0 
Surviving the AI revolution 14 7,6 
None 6 3,3 
Other 2 1,1 
Total 184 100,0 
 
In this video we hear Dr. Eric Topol, an expert in digital medicine, saying that 
“many conditions could be AI-diagnosed”.  
Q19: When do you think this will become a reality? 
 Frequency Percentage 
In 2 years 19 10,3 
In 4 years 15 8,2 
In 6 years 25 13,6 
In 10 years 75 40,8 
In 15 or more years 43 23,4 
Never 7 3,8 
Total 184 100,0 
 
 
 
 
55 
 
Q20: How does this scenario make you feel? Choose up to 3 options 
 Frequency Percentage 
Fear 23 12,5 
Relief 9 4,9 
Indifference 37 20,1 
Excitement 82 44,6 
Motivation 63 34,2 
Demotivation 10 5,4 
Other 13 7,1 
 
Q21: How likely is it that neuroradiologists who use AI will replace 
neuroradiologists who don't? 
 Frequency Percentage 
Very unlikely 13 7,1 
Unlikely 39 21,2 
No opinion 36 19,6 
Likely 74 40,2 
Very likely 22 12,0 
Total 184 100,0 
 
 
 
 
 
 
 
 
 
 
 
 
 
Q22: In this scenario of AI automation what would be your major 
concerns? (Choose up to 3 options) 
 Frequency Percentage 
Lower salaries and/or job opportunities 45 24,5 
Lower reputation, as neuroradiologists 
would no longer perform certain tasks 
30 16,3 
Ethical issues related to patients’ data 
privacy and security 
72 39,1 
Threat to doctor-patient relationship 37 20,1 
Regulatory concerns (e.g. lack of standard 
regulation, liability issues) 
94 51,1 
Technological concerns regarding AI 
malfunction (e.g. making a wrong decision 
based on a AI error) 
145 78,8 
Other 9 4,9 
56 
 
Q23a. Imagine the following situation: "You work in a hospital/institution and the 
Administration calls you to discuss about AI in the medical field" 
What are your initial thoughts? 
 Frequency Percentage 
I don't want to hear about this 1 0,5 
I am too busy for IT stuff 8 4,3 
I don't want to be replaced by AI, don't count with me 4 2,2 
I want to be involved 109 59,2 
I want to help push this process forward 32 17,4 
Wow! I want to be ahead of the game, I am in! 30 16,3 
Total 184 100,0 
 
Q23b. Which of the following steps would you recommend to accelerate the process? 
Choose up to 3 options 
  Frequency Percentage 
Invest in AI literacy and training for healthcare 
professionals 
79 42,9 
Upgrade the current IT infrastructures for a better 
support to AI tools 
97 52,7 
Promote the collaboration of healthcare professionals 
in developing/improving AI solutions 
97 52,7 
Establish a multidisciplinary team of AI experts in 
charge of overseeing the process 
85 46,2 
Create specific protocols for risk management of AI-
related problems 
60 32,6 
Other 7 3,8 